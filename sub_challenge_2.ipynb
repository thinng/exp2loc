{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering locations into groups of similar coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import MeanShift, estimate_bandwidth\n",
    "# in-situ coordinates\n",
    "insitu_coords = pd.read_csv('geometry.txt',sep=' ')\n",
    "\n",
    "y = insitu_coords[['xcoord','ycoord','zcoord']].values\n",
    "bw = estimate_bandwidth(y, quantile=.01)\n",
    "ms = MeanShift(bandwidth=bw, bin_seeding=True, min_bin_freq=5)\n",
    "ms.fit(y)\n",
    "# store coordinates for the centers of the clusters\n",
    "cluster_centers = ms.cluster_centers_\n",
    "np.save('cluster_centers.npy',cluster_centers)\n",
    "\n",
    "# store what cluster the insitu coordinates belong to\n",
    "cluster_label = list(ms.labels_)\n",
    "with open('cluster_label.txt','w') as f:\n",
    "    f.write('\\n'.join(map(str,cluster_label)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import math\n",
    "import sklearn.cluster\n",
    "from skfeature.utility.construct_W import construct_W\n",
    "from skfeature.utility.sparse_learning import feature_ranking\n",
    "\n",
    "def ndfs(X, **kwargs):\n",
    "    \"\"\"\n",
    "    This function implement unsupervised feature selection using nonnegative spectral analysis, i.e.,\n",
    "    min_{F,W} Tr(F^T L F) + alpha*(||XW-F||_F^2 + beta*||W||_{2,1}) + gamma/2 * ||F^T F - I||_F^2\n",
    "    s.t. F >= 0\n",
    "    \n",
    "    Input\n",
    "    -----\n",
    "    X: {numpy array}, shape (n_samples, n_features)\n",
    "        input data\n",
    "    kwargs: {dictionary}\n",
    "        W: {sparse matrix}, shape {n_samples, n_samples}\n",
    "            affinity matrix\n",
    "        alpha: {float}\n",
    "            Parameter alpha in objective function\n",
    "        beta: {float}\n",
    "            Parameter beta in objective function\n",
    "        gamma: {float}\n",
    "            a very large number used to force F^T F = I\n",
    "        F0: {numpy array}, shape (n_samples, n_clusters)\n",
    "            initialization of the pseudo label matirx F, if not provided\n",
    "        n_clusters: {int}\n",
    "            number of clusters\n",
    "        verbose: {boolean}\n",
    "            True if user want to print out the objective function value in each iteration, false if not\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    W: {numpy array}, shape(n_features, n_clusters)\n",
    "        feature weight matrix\n",
    "        \n",
    "    Reference: \n",
    "        Li, Zechao, et al. \"Unsupervised Feature Selection Using Nonnegative Spectral Analysis.\" AAAI. 2012.\n",
    "    \"\"\"\n",
    "\n",
    "    # default gamma is 10e8\n",
    "    if 'gamma' not in kwargs:\n",
    "        gamma = 10e8\n",
    "    else:\n",
    "        gamma = kwargs['gamma']\n",
    "    # use the default affinity matrix\n",
    "    if 'W' not in kwargs:\n",
    "        W = construct_W(X)\n",
    "    else:\n",
    "        W = kwargs['W']\n",
    "    if 'alpha' not in kwargs:\n",
    "        alpha = 1\n",
    "    else:\n",
    "        alpha = kwargs['alpha']\n",
    "    if 'beta' not in kwargs:\n",
    "        beta = 1\n",
    "    else:\n",
    "        beta = kwargs['beta']\n",
    "    if 'F0' not in kwargs:\n",
    "        # initialize F\n",
    "        n_clusters = kwargs['n_clusters']\n",
    "        F = kmeans_initialization(X, n_clusters)\n",
    "    else:\n",
    "        F = kwargs['F0']\n",
    "    if 'verbose' not in kwargs:\n",
    "        verbose = False\n",
    "    else:\n",
    "        verbose = kwargs['verbose']\n",
    "    \n",
    "    n_samples, n_features = X.shape\n",
    "\n",
    "    # initialize D as identity matrix\n",
    "    D = np.identity(n_features)\n",
    "    I = np.identity(n_samples)\n",
    "\n",
    "    # build laplacian matrix\n",
    "    L = np.array(W.sum(1))[:, 0] - W\n",
    "\n",
    "    max_iter = 1000\n",
    "    obj = np.zeros(max_iter)\n",
    "    for iter_step in range(max_iter):\n",
    "        # update W\n",
    "        T = np.linalg.inv(np.dot(X.transpose(), X) + beta * D + 1e-6*np.eye(n_features))\n",
    "        W = np.dot(np.dot(T, X.transpose()), F)\n",
    "        # update D\n",
    "        temp = np.sqrt((W*W).sum(1))\n",
    "        temp[temp < 1e-16] = 1e-16\n",
    "        temp = 0.5 / temp\n",
    "        D = np.diag(temp)\n",
    "        # update M\n",
    "        M = L + alpha * (I - np.dot(np.dot(X, T), X.transpose()))\n",
    "        M = (M + M.transpose())/2\n",
    "        # update F\n",
    "        denominator = np.dot(M, F) + gamma*np.dot(np.dot(F, F.transpose()), F)\n",
    "        temp = np.divide(gamma*F, denominator)\n",
    "        F = F*np.array(temp)\n",
    "        temp = np.diag(np.sqrt(np.diag(1 / (np.dot(F.transpose(), F) + 1e-16))))\n",
    "        F = np.dot(F, temp)\n",
    "\n",
    "        # calculate objective function\n",
    "        obj[iter_step] = np.trace(np.dot(np.dot(F.transpose(), M), F)) + gamma/4*np.linalg.norm(np.dot(F.transpose(), F)-np.identity(n_clusters), 'fro')\n",
    "        if verbose:\n",
    "            print('obj at iter {0}: {1}'.format(iter_step+1, obj[iter_step]))\n",
    "\n",
    "        if iter_step >= 1 and math.fabs(obj[iter_step] - obj[iter_step-1]) < 1e-3:\n",
    "            break\n",
    "    return W\n",
    "\n",
    "\n",
    "def kmeans_initialization(X, n_clusters):\n",
    "    \"\"\"\n",
    "    This function uses kmeans to initialize the pseudo label\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "    X: {numpy array}, shape (n_samples, n_features)\n",
    "        input data\n",
    "    n_clusters: {int}\n",
    "        number of clusters\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    Y: {numpy array}, shape (n_samples, n_clusters)\n",
    "        pseudo label matrix\n",
    "    \"\"\"\n",
    "\n",
    "    n_samples, n_features = X.shape\n",
    "    kmeans = sklearn.cluster.KMeans(n_clusters=n_clusters, init='k-means++', n_init=10, max_iter=300,\n",
    "                                    tol=0.0001, precompute_distances=True, verbose=0,\n",
    "                                    random_state=4, copy_x=True, n_jobs=1)\n",
    "    kmeans.fit(X)\n",
    "    labels = kmeans.labels_\n",
    "    Y = np.zeros((n_samples, n_clusters))\n",
    "    for row in range(0, n_samples):\n",
    "        Y[row, labels[row]] = 1\n",
    "    T = np.dot(Y.transpose(), Y)\n",
    "    F = np.dot(Y, np.sqrt(np.linalg.inv(T)))\n",
    "    F = F + 0.02*np.ones((n_samples, n_clusters))\n",
    "    return F\n",
    "\n",
    "\n",
    "def calculate_obj(X, W, F, L, alpha, beta):\n",
    "    \"\"\"\n",
    "    This function calculates the objective function of NDFS\n",
    "    \"\"\"\n",
    "    # Tr(F^T L F)\n",
    "    T1 = np.trace(np.dot(np.dot(F.transpose(), L), F))\n",
    "    T2 = np.linalg.norm(np.dot(X, W) - F, 'fro')\n",
    "    T3 = (np.sqrt((W*W).sum(1))).sum()\n",
    "    obj = T1 + alpha*(T2 + beta*T3)\n",
    "    return obj\n",
    "\n",
    "\n",
    "# Get marker genes from in situ data\n",
    "insitu_df = pd.read_csv('bdtnp.txt',sep='\\t')\n",
    "marker_genes = list(insitu_df.columns)\n",
    "\n",
    "# Get expression of marker genes for cells\n",
    "cell_df = pd.read_csv('dge_normalized.txt',sep='\\t')\n",
    "all_genes = list(cell_df.index)  \n",
    "cell_df = cell_df.T\n",
    "cell_df.columns = all_genes\n",
    "cell_df = cell_df[marker_genes]\n",
    "\n",
    "# rank features using NDFS feature selection method\n",
    "with open('fs_ndfs_40.txt', 'w') as f:\n",
    "    # construct affinity matrix\n",
    "    kwargs = {\"metric\": 'euclidean', \"neighborMode\": \"knn\", \"weightMode\": 'heat_kernel', \"k\": 5, 't': 1}\n",
    "    W = construct_W(cell_df.values, **kwargs)\n",
    "    # obtain the feature weight matrix\n",
    "    score = ndfs(cell_df.values, W=W, n_clusters=5)#len(set([int(e) for e in open('data/cluster_label.txt')]))\n",
    "    # sort the feature scores in an ascending order according to the feature scores\n",
    "    idx = feature_ranking(score)\n",
    "    ls = [marker_genes[e] for e in idx][:40]\n",
    "    f.write('\\n'.join(ls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Location prediction for cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import tensorflow as tf\n",
    "import scipy\n",
    "\n",
    "# this function returns MCC score for true_labels and pred_labels vectors\n",
    "def get_mcc(true_labels, pred_labels):\n",
    "    TP = np.sum(np.logical_and(pred_labels == 1, true_labels == 1))\n",
    "    TN = np.sum(np.logical_and(pred_labels == 0, true_labels == 0))\n",
    "    FP = np.sum(np.logical_and(pred_labels == 1, true_labels == 0))\n",
    "    FN = np.sum(np.logical_and(pred_labels == 0, true_labels == 1))\n",
    "    mcc = (TP * TN) - (FP * FN)\n",
    "    denom = np.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))\n",
    "    if denom==0:\n",
    "        return 0\n",
    "    return mcc / denom\n",
    "\n",
    "# turn the probability to the clusters of the cell to the weighted coordinates of the cluster centers\n",
    "def get_xyz(x):\n",
    "    ret = []\n",
    "    for i in range(len(x)):\n",
    "        v = np.average(cluster_centers, axis=0, weights=x[i,:])\n",
    "        ret += [ v ]\n",
    "    return np.array(ret)\n",
    "\n",
    "# in-situ binary expression\n",
    "insitu_bin = pd.read_csv('binarized_bdtnp.csv')\n",
    "# in-situ coordinates\n",
    "insitu_coords = pd.read_csv('geometry.txt',sep=' ')\n",
    "\n",
    "# cell binary expression\n",
    "cell_bin = pd.read_csv('dge_binarized_distMap.csv')\n",
    "all_genes = list(cell_bin.index)  \n",
    "cell_bin = cell_bin.T\n",
    "cell_bin.columns = all_genes\n",
    "\n",
    "labels = [int(e) for e in open('cluster_label.txt')]\n",
    "labels = np.array(labels)\n",
    "cluster_centers = np.load('cluster_centers.npy')\n",
    "\n",
    "\n",
    "genes = [e.strip() for e in open('fs_ndfs_40.txt') if e.strip()]\n",
    "clf = KNeighborsClassifier(n_neighbors=10, leaf_size=1, metric='matching')\n",
    "# learn a multi-class classifier\n",
    "clf.fit(insitu_bin[genes].values, labels)\n",
    "# predict probability of cells to the clusters\n",
    "preds = clf.predict_proba(cell_bin[genes].values)\n",
    "# turn the probabilities to average weighted coordinates\n",
    "preds = get_xyz(preds)\n",
    "# distance to the in situ coordinates of the predicted coordinates for cells\n",
    "preds_to_insitu_coords = scipy.spatial.distance.cdist(preds,insitu_coords[['xcoord','ycoord','zcoord']].values)\n",
    "\n",
    "# choose 10 best locations\n",
    "TOP = 10\n",
    "# store indices of locations for all cells\n",
    "indices = []\n",
    "for i in range(len(preds_to_insitu_coords)):\n",
    "#     get the index of the location whose the smallest to insitu coords\n",
    "    best_idx = preds_to_insitu_coords[i].argmin()\n",
    "#     get coordinates for the location\n",
    "    coord = insitu_coords[ insitu_coords.index==best_idx ][['xcoord','ycoord','zcoord']].values\n",
    "#     compared the coord with all the coords    \n",
    "    dist = scipy.spatial.distance.cdist(coord, insitu_coords[['xcoord','ycoord','zcoord']].values)[0]\n",
    "#     get the locations with shortest Euclidean distance\n",
    "    top_idx = dist.argsort()[:TOP]\n",
    "#     +1 as the location starts from 1\n",
    "    top_idx = [e+1 for e in top_idx]\n",
    "    indices += [ top_idx ]\n",
    "\n",
    "\n",
    "dout = '40genes.csv' \n",
    "with open(dout,'w') as file_result:\n",
    "    tmp = ['']\n",
    "    for i in range(len(genes)):\n",
    "        tmp += [ genes[i] ]\n",
    "        if (i+1)%10==0:\n",
    "            file_result.write(','.join(tmp) + '\\n')\n",
    "            tmp = ['']\n",
    "    for i in range(len(indices)):\n",
    "        tmp = [i+1] + indices[i]\n",
    "        file_result.write(','.join(map(str,tmp)) + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
