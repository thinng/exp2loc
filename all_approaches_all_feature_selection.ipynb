{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running result/sc1_direct_variance.csv\n",
      "running result/sc1_indirect_variance.csv\n",
      "running result/sc1_direct_ndfs.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:786: FutureWarning: 'precompute_distances' was deprecated in version 0.23 and will be removed in 1.0 (renaming of 0.25). It has no effect\n",
      "  warnings.warn(\"'precompute_distances' was deprecated in version \"\n",
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:792: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 1.0 (renaming of 0.25).\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running result/sc1_indirect_ndfs.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:786: FutureWarning: 'precompute_distances' was deprecated in version 0.23 and will be removed in 1.0 (renaming of 0.25). It has no effect\n",
      "  warnings.warn(\"'precompute_distances' was deprecated in version \"\n",
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:792: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 1.0 (renaming of 0.25).\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running result/sc1_direct_mcfs.csv\n",
      "running result/sc1_indirect_mcfs.csv\n",
      "running result/sc2_direct_variance.csv\n",
      "running result/sc2_indirect_variance.csv\n",
      "running result/sc2_direct_ndfs.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:786: FutureWarning: 'precompute_distances' was deprecated in version 0.23 and will be removed in 1.0 (renaming of 0.25). It has no effect\n",
      "  warnings.warn(\"'precompute_distances' was deprecated in version \"\n",
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:792: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 1.0 (renaming of 0.25).\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running result/sc2_indirect_ndfs.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:786: FutureWarning: 'precompute_distances' was deprecated in version 0.23 and will be removed in 1.0 (renaming of 0.25). It has no effect\n",
      "  warnings.warn(\"'precompute_distances' was deprecated in version \"\n",
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:792: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 1.0 (renaming of 0.25).\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running result/sc2_direct_mcfs.csv\n",
      "running result/sc2_indirect_mcfs.csv\n",
      "running result/sc3_direct_variance.csv\n",
      "running result/sc3_indirect_variance.csv\n",
      "running result/sc3_direct_ndfs.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:786: FutureWarning: 'precompute_distances' was deprecated in version 0.23 and will be removed in 1.0 (renaming of 0.25). It has no effect\n",
      "  warnings.warn(\"'precompute_distances' was deprecated in version \"\n",
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:792: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 1.0 (renaming of 0.25).\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running result/sc3_indirect_ndfs.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:786: FutureWarning: 'precompute_distances' was deprecated in version 0.23 and will be removed in 1.0 (renaming of 0.25). It has no effect\n",
      "  warnings.warn(\"'precompute_distances' was deprecated in version \"\n",
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:792: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 1.0 (renaming of 0.25).\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running result/sc3_direct_mcfs.csv\n",
      "running result/sc3_indirect_mcfs.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy,sys,math\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from skfeature.function.sparse_learning_based import MCFS\n",
    "from sklearn.cluster import MeanShift, estimate_bandwidth\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import sklearn.cluster\n",
    "from skfeature.utility.construct_W import construct_W\n",
    "\n",
    "# this function returns MCC score for true_labels and pred_labels vectors\n",
    "def get_mcc(true_labels, pred_labels):\n",
    "    TP = np.sum(np.logical_and(pred_labels == 1, true_labels == 1))\n",
    "    TN = np.sum(np.logical_and(pred_labels == 0, true_labels == 0))\n",
    "    FP = np.sum(np.logical_and(pred_labels == 1, true_labels == 0))\n",
    "    FN = np.sum(np.logical_and(pred_labels == 0, true_labels == 1))\n",
    "    mcc = (TP * TN) - (FP * FN)\n",
    "    denom = np.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))\n",
    "    if denom==0:\n",
    "        return 0\n",
    "    return mcc / denom\n",
    "\n",
    "# turn the probability to the clusters of the cell to the weighted coordinates of the cluster centers\n",
    "def get_xyz(x):\n",
    "    ret = []\n",
    "    for i in range(len(x)):\n",
    "        v = np.average(cluster_centers, axis=0, weights=x[i,:])\n",
    "        ret += [ v ]\n",
    "    return np.array(ret)\n",
    "\n",
    "# ndfs feature selection \n",
    "# Li, Zechao, et al. \"Unsupervised Feature Selection Using Nonnegative Spectral Analysis.\" AAAI. 2012.\n",
    "def ndfs(X, n_clusters):\n",
    "    gamma = 10e8\n",
    "    W = construct_W(X)\n",
    "    alpha = 1\n",
    "    beta = 1\n",
    "    n_samples, n_features = X.shape\n",
    "    kmeans = sklearn.cluster.KMeans(n_clusters=n_clusters, init='k-means++', n_init=10, max_iter=300,\n",
    "                                    tol=0.0001, precompute_distances=True, verbose=0,\n",
    "                                    random_state=42, copy_x=True, n_jobs=1)\n",
    "    kmeans.fit(X)\n",
    "    labels = kmeans.labels_\n",
    "    Y = np.zeros((n_samples, n_clusters))\n",
    "    for row in range(0, n_samples):\n",
    "        Y[row, labels[row]] = 1\n",
    "    T = np.dot(Y.transpose(), Y)\n",
    "    F = np.dot(Y, np.sqrt(np.linalg.inv(T)))\n",
    "    F = F + 0.02*np.ones((n_samples, n_clusters))            \n",
    "    \n",
    "    # initialize D as identity matrix\n",
    "    D = np.identity(n_features)\n",
    "    I = np.identity(n_samples)\n",
    "    # build laplacian matrix\n",
    "    L = np.array(W.sum(1))[:, 0] - W\n",
    "\n",
    "    max_iter = 1000\n",
    "    obj = np.zeros(max_iter)\n",
    "    for iter_step in range(max_iter):\n",
    "        # update W\n",
    "        T = np.linalg.inv(np.dot(X.transpose(), X) + beta * D + 1e-6*np.eye(n_features))\n",
    "        W = np.dot(np.dot(T, X.transpose()), F)\n",
    "        # update D\n",
    "        temp = np.sqrt((W*W).sum(1))\n",
    "        temp[temp < 1e-16] = 1e-16\n",
    "        temp = 0.5 / temp\n",
    "        D = np.diag(temp)\n",
    "        # update M\n",
    "        M = L + alpha * (I - np.dot(np.dot(X, T), X.transpose()))\n",
    "        M = (M + M.transpose())/2\n",
    "        # update F\n",
    "        denominator = np.dot(M, F) + gamma*np.dot(np.dot(F, F.transpose()), F)\n",
    "        temp = np.divide(gamma*F, denominator)\n",
    "        F = F*np.array(temp)\n",
    "        temp = np.diag(np.sqrt(np.diag(1 / (np.dot(F.transpose(), F) + 1e-16))))\n",
    "        F = np.dot(F, temp)\n",
    "        # calculate objective function\n",
    "        obj[iter_step] = np.trace(np.dot(np.dot(F.transpose(), M), F)) + gamma/4*np.linalg.norm(np.dot(F.transpose(), F)-np.identity(n_clusters), 'fro')\n",
    "        if iter_step >= 1 and math.fabs(obj[iter_step] - obj[iter_step-1]) < 1e-3:\n",
    "            break\n",
    "    return W\n",
    "\n",
    "# this function returns a ranking of features for a feature selection method  \n",
    "def feat_ranking(fs):\n",
    "    idx = None\n",
    "    # Get expression of marker genes for cells\n",
    "    cell_df = pd.read_csv('data/dge_normalized.txt',sep='\\t')\n",
    "    all_genes = list(cell_df.index)  \n",
    "    cell_df = cell_df.T\n",
    "    cell_df.columns = all_genes\n",
    "    cell_df = cell_df[marker_genes]\n",
    "    \n",
    "    if fs=='variance':\n",
    "        sel = VarianceThreshold()\n",
    "        sel.fit(cell_df.values)\n",
    "        score = sel.variances_\n",
    "        idx = np.argsort(score, 0)[::-1]\n",
    "    elif fs=='ndfs':\n",
    "        W = ndfs(cell_df.values,n_clusters=10) \n",
    "        score = (W*W).sum(1)\n",
    "        idx = np.argsort(score)[::-1]          \n",
    "    elif fs=='mcfs':\n",
    "        score = MCFS.mcfs(cell_df.values)\n",
    "        idx = np.argsort(score)[::-1]\n",
    "    return idx\n",
    "    \n",
    "# feat_selections = ['variance','ndfs','mcfs']\n",
    "# loc_predictions = ['direct','indirect','indirect']\n",
    "\n",
    "num_feats = [60,40,20]\n",
    "scs = [1,2,3]\n",
    "nfeat_sc = dict(zip(num_feats,scs))\n",
    "\n",
    "\n",
    "\n",
    "# Get marker genes from in situ data\n",
    "insitu_df = pd.read_csv('data/bdtnp.txt',sep='\\t')\n",
    "marker_genes = list(insitu_df.columns)\n",
    "# in-situ binary expression\n",
    "insitu_bin = pd.read_csv('data/binarized_bdtnp.csv')\n",
    "# # in-situ coordinates\n",
    "insitu_coords = pd.read_csv('data/geometry.txt',sep=' ')\n",
    "\n",
    "# cell binary expression\n",
    "cell_bin = pd.read_csv('data/dge_binarized_distMap.csv')\n",
    "all_genes = list(cell_bin.index)  \n",
    "cell_bin = cell_bin.T\n",
    "cell_bin.columns = all_genes\n",
    "\n",
    "for num_feat in [60,40,20]:\n",
    "    for feat_selection in ['variance','ndfs','mcfs']:\n",
    "        for loc_prediction in ['direct','indirect']:\n",
    "            dout =  'result/' + 'sc' + str(nfeat_sc[num_feat]) + '_' + loc_prediction + '_' +  feat_selection +  '.csv' \n",
    "            print('running',dout)\n",
    "        \n",
    "            idx = feat_ranking(feat_selection)\n",
    "            # use best num_feat genes\n",
    "            genes = [marker_genes[e] for e in idx][:num_feat]\n",
    "            if loc_prediction=='direct':\n",
    "                # compute MCC for all cells with all locations\n",
    "                Pr = cell_bin[genes].values\n",
    "                Gt = insitu_bin[genes].values\n",
    "                mcc = np.asarray([get_mcc(p, g) for p in Pr for g in Gt])\n",
    "                mcc = mcc.reshape(len(Pr),-1)\n",
    "                # choose 10 best locations\n",
    "                TOP = 10\n",
    "                # store indices of locations for all cells\n",
    "                indices = []\n",
    "                # loop over all cells\n",
    "                for i in range(len(mcc)):\n",
    "                #     get the location whose the largest mcc\n",
    "                    best_idx = mcc[i].argmax()\n",
    "                #     get coordinates for the location\n",
    "                    coord = insitu_coords[ insitu_coords.index==best_idx ][['xcoord','ycoord','zcoord']].values\n",
    "                #     compared the coord with all the coords    \n",
    "                    dist = scipy.spatial.distance.cdist(coord, insitu_coords[['xcoord','ycoord','zcoord']].values)[0]\n",
    "                #     get the locations with shortest Euclidean distance\n",
    "                    top_idx = dist.argsort()[:TOP]\n",
    "                #     +1 as the location starts from 1\n",
    "                    top_idx = [e+1 for e in top_idx]\n",
    "                    indices += [ top_idx ]\n",
    "            else: # clustering first then classification\n",
    "                # Step 1: Clustering locations into groups of similar coordinates\n",
    "                # in-situ coordinates\n",
    "                insitu_coords = pd.read_csv('data/geometry.txt',sep=' ')\n",
    "                y = insitu_coords[['xcoord','ycoord','zcoord']].values\n",
    "                bw = estimate_bandwidth(y, quantile=.01)\n",
    "                ms = MeanShift(bandwidth=bw, bin_seeding=True, min_bin_freq=5)\n",
    "                ms.fit(y)\n",
    "                # store coordinates for the centers of the clusters\n",
    "                cluster_centers = ms.cluster_centers_\n",
    "                # store what cluster the insitu coordinates belong to\n",
    "                labels = ms.labels_\n",
    "\n",
    "                # Step 2: Classification\n",
    "\n",
    "                clf = KNeighborsClassifier()\n",
    "                # learn a multi-class classifier\n",
    "                clf.fit(insitu_bin[genes].values, labels)\n",
    "                # predict probability of cells to the clusters\n",
    "                preds = clf.predict_proba(cell_bin[genes].values)\n",
    "                # turn the probabilities to average weighted coordinates\n",
    "                preds = get_xyz(preds)\n",
    "                # distance to the in situ coordinates of the predicted coordinates for cells\n",
    "                preds_to_insitu_coords = scipy.spatial.distance.cdist(preds,insitu_coords[['xcoord','ycoord','zcoord']].values)\n",
    "                # choose 10 best locations\n",
    "                TOP = 10\n",
    "                # store indices of locations for all cells\n",
    "                indices = []\n",
    "                for i in range(len(preds_to_insitu_coords)):\n",
    "                #     get the index of the location whose the smallest to insitu coords\n",
    "                    best_idx = preds_to_insitu_coords[i].argmin()\n",
    "                #     get coordinates for the location\n",
    "                    coord = insitu_coords[ insitu_coords.index==best_idx ][['xcoord','ycoord','zcoord']].values\n",
    "                #     compared the coord with all the coords    \n",
    "                    dist = scipy.spatial.distance.cdist(coord, insitu_coords[['xcoord','ycoord','zcoord']].values)[0]\n",
    "                #     get the locations with shortest Euclidean distance\n",
    "                    top_idx = dist.argsort()[:TOP]\n",
    "                #     +1 as the location starts from 1\n",
    "                    top_idx = [e+1 for e in top_idx]\n",
    "                    indices += [ top_idx ]        \n",
    "\n",
    "            # submission file\n",
    "            with open(dout,'w') as file_result:\n",
    "                tmp = ['']\n",
    "                for i in range(len(genes)):\n",
    "                    tmp += [ genes[i] ]\n",
    "                    if (i+1)%10==0:\n",
    "                        file_result.write(','.join(tmp) + '\\n')\n",
    "                        tmp = ['']\n",
    "                for i in range(len(indices)):\n",
    "                    tmp = [i+1] + indices[i]\n",
    "                    file_result.write(','.join(map(str,tmp)) + '\\n')        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
